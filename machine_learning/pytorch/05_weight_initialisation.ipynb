{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3be820-45f7-4a6d-ab49-2edcbba986a7",
   "metadata": {},
   "source": [
    "# Weight initialisation techniques in PyTorch\n",
    "\n",
    "Data used for this notebook is from a Kaggle competition  \n",
    "Link to the competition: https://www.kaggle.com/c/santander-customer-transaction-prediction  \n",
    "Type of Problem: Classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6036b3-c176-45a4-82e2-05c48c59de55",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a2be68-51fc-4c0f-a946-b90c614f7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42486aec-1a7a-4049-8321-925fba6c8733",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c15e93-a26a-4631-8678-5b56f4f9eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.093</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.389</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2  var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.093  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.389  12.3622  7.0433  5.6208   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "\n",
       "[2 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e519dd-9e8b-432d-9079-2b55156d001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d1975-83c4-489f-a8d2-2c0f7afc6fce",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b88cbe2-de8d-4808-8dff-e87d8ec26f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_columns = [c for c in df_train.columns if c not in ('ID_code','target')]\n",
    "len(var_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37d69e3-0eae-4640-b065-b2718a097ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>0.527761</td>\n",
       "      <td>0.498848</td>\n",
       "      <td>0.516818</td>\n",
       "      <td>0.517698</td>\n",
       "      <td>0.551997</td>\n",
       "      <td>0.501877</td>\n",
       "      <td>0.501123</td>\n",
       "      <td>0.522330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532601</td>\n",
       "      <td>0.521950</td>\n",
       "      <td>0.470032</td>\n",
       "      <td>0.502746</td>\n",
       "      <td>0.483477</td>\n",
       "      <td>0.536917</td>\n",
       "      <td>0.507605</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.483899</td>\n",
       "      <td>0.527460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.159324</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.154463</td>\n",
       "      <td>0.139968</td>\n",
       "      <td>0.157852</td>\n",
       "      <td>0.142057</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.161333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140158</td>\n",
       "      <td>0.155773</td>\n",
       "      <td>0.121015</td>\n",
       "      <td>0.132779</td>\n",
       "      <td>0.162998</td>\n",
       "      <td>0.149925</td>\n",
       "      <td>0.167666</td>\n",
       "      <td>0.152592</td>\n",
       "      <td>0.152223</td>\n",
       "      <td>0.154974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404160</td>\n",
       "      <td>0.405322</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.400217</td>\n",
       "      <td>0.414637</td>\n",
       "      <td>0.428839</td>\n",
       "      <td>0.396761</td>\n",
       "      <td>0.384659</td>\n",
       "      <td>0.396368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431376</td>\n",
       "      <td>0.404422</td>\n",
       "      <td>0.385063</td>\n",
       "      <td>0.411373</td>\n",
       "      <td>0.360573</td>\n",
       "      <td>0.429027</td>\n",
       "      <td>0.376952</td>\n",
       "      <td>0.379516</td>\n",
       "      <td>0.380712</td>\n",
       "      <td>0.410436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508191</td>\n",
       "      <td>0.528530</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.556658</td>\n",
       "      <td>0.497967</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.527633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531653</td>\n",
       "      <td>0.517279</td>\n",
       "      <td>0.467860</td>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.481614</td>\n",
       "      <td>0.533706</td>\n",
       "      <td>0.510850</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.534987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620387</td>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.603369</td>\n",
       "      <td>0.632294</td>\n",
       "      <td>0.619692</td>\n",
       "      <td>0.672246</td>\n",
       "      <td>0.599256</td>\n",
       "      <td>0.615573</td>\n",
       "      <td>0.650798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630091</td>\n",
       "      <td>0.628818</td>\n",
       "      <td>0.553659</td>\n",
       "      <td>0.598340</td>\n",
       "      <td>0.608396</td>\n",
       "      <td>0.638836</td>\n",
       "      <td>0.638353</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.594820</td>\n",
       "      <td>0.648661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490       0.515985       0.527761       0.498848   \n",
       "std         0.300653       0.152716       0.159324       0.153221   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.404160       0.405322       0.383234   \n",
       "50%         0.000000       0.508191       0.528530       0.491004   \n",
       "75%         0.000000       0.620387       0.645236       0.603369   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.516818       0.517698       0.551997       0.501877   \n",
       "std         0.154463       0.139968       0.157852       0.142057   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.400217       0.414637       0.428839       0.396761   \n",
       "50%         0.518970       0.520277       0.556658       0.497967   \n",
       "75%         0.632294       0.619692       0.672246       0.599256   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.501123       0.522330  ...       0.532601       0.521950   \n",
       "std         0.152988       0.161333  ...       0.140158       0.155773   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.384659       0.396368  ...       0.431376       0.404422   \n",
       "50%         0.497138       0.527633  ...       0.531653       0.517279   \n",
       "75%         0.615573       0.650798  ...       0.630091       0.628818   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.470032       0.502746       0.483477       0.536917   \n",
       "std         0.121015       0.132779       0.162998       0.149925   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.385063       0.411373       0.360573       0.429027   \n",
       "50%         0.467860       0.504894       0.481614       0.533706   \n",
       "75%         0.553659       0.598340       0.608396       0.638836   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        0.507605       0.488022       0.483899       0.527460  \n",
       "std         0.167666       0.152592       0.152223       0.154974  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.376952       0.379516       0.380712       0.410436  \n",
       "50%         0.510850       0.484718       0.487100       0.534987  \n",
       "75%         0.638353       0.601460       0.594820       0.648661  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_train[var_columns] = scaler.fit_transform(df_train[var_columns])\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d149ff-afbe-48db-b8ca-e66ab168014c",
   "metadata": {},
   "source": [
    "Split training data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26f0391-2a89-4e55-b489-00bf44cca761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = df_train.loc[:, var_columns].to_numpy()\n",
    "y_np = df_train.loc[:, 'target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912841b7-b056-4932-89ed-1df681b119d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba1a41c-64ec-4fbe-b734-0981d29fd13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160000, 200]),\n",
       " torch.Size([40000, 200]),\n",
       " torch.Size([160000, 1]),\n",
       " torch.Size([40000, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d8c88-3807-470f-812f-4cd56fee4231",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Default weight initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29c731d0-8898-4037-8988-4f520670ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 10)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32efd667-128b-4a82-b297-517c7c35075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    batch_size = 1000\n",
    "    n_epochs = 15\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in range(0, X_train.shape[0], batch_size):\n",
    "\n",
    "            # Get data in batches\n",
    "            X_train_batch = X_train[b:b+batch_size]\n",
    "            y_train_batch = y_train[b:b+batch_size]\n",
    "\n",
    "            # Make predictions\n",
    "            y_train_batch_pred = model(X_train_batch)\n",
    "            y_val_pred = model(X_val)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_train = loss_fn(y_train_batch_pred, y_train_batch)\n",
    "            loss_val = loss_fn(y_val_pred, y_val)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}, training loss {loss_train}, validation loss {loss_val}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8ce806-7039-4509-a279-e5ab7731fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auc(model, X_val, y_val):\n",
    "    y_val_pred = model(X_val)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_val.detach().numpy(), y_val_pred.detach().numpy())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59f98f53-e427-4c8c-88ee-32f4d14bbd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.20981259644031525, validation loss 0.27239277958869934\n",
      "Epoch 1, training loss 0.18198689818382263, validation loss 0.2407095730304718\n",
      "Epoch 2, training loss 0.18049003183841705, validation loss 0.2396184504032135\n",
      "Epoch 3, training loss 0.181327223777771, validation loss 0.2433619350194931\n",
      "Epoch 4, training loss 0.18051311373710632, validation loss 0.24122726917266846\n",
      "Epoch 5, training loss 0.18088243901729584, validation loss 0.2419077605009079\n",
      "Epoch 6, training loss 0.18101944029331207, validation loss 0.24195095896720886\n",
      "Epoch 7, training loss 0.1809610277414322, validation loss 0.24128766357898712\n",
      "Epoch 8, training loss 0.18088066577911377, validation loss 0.24092021584510803\n",
      "Epoch 9, training loss 0.18076667189598083, validation loss 0.2405151128768921\n",
      "Epoch 10, training loss 0.18068315088748932, validation loss 0.2401895970106125\n",
      "Epoch 11, training loss 0.18060536682605743, validation loss 0.23987551033496857\n",
      "Epoch 12, training loss 0.1805875599384308, validation loss 0.23971500992774963\n",
      "Epoch 13, training loss 0.18059034645557404, validation loss 0.23954780399799347\n",
      "Epoch 14, training loss 0.18058373034000397, validation loss 0.23936232924461365\n",
      "\n",
      "ROC AUC: 0.8591475773572124\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model = train_model(model)\n",
    "\n",
    "print_auc(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a8af8-6fb9-403a-86e2-2381046f114f",
   "metadata": {},
   "source": [
    "## 2. Zero Initialization\n",
    "\n",
    "- Setting all weights to zero\n",
    "- While simple, it's generally not recommended the network will not be able to learn any meaningful patterns\n",
    "- Also, if all weights are set to the same non-zero value, the neurons in the same layer would learn the same features and may not break symmetry during training\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.zeros_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "124acd25-26be-4eb9-9bdf-2efc2105fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelZero(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelZero, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 10)\n",
    "        nn.init.zeros_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        nn.init.zeros_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38fc4c8e-8202-44b3-8df1-951de1d03f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelZero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bdcc237-5889-4f26-9c30-24c51f311451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "fc1.weight tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "fc1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "fc2.weight tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "fc2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978aee72-6804-43a6-b62a-ca878980062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.27075910568237305, validation loss 0.33037933707237244\n",
      "Epoch 1, training loss 0.270715594291687, validation loss 0.3303798735141754\n",
      "Epoch 2, training loss 0.2708769142627716, validation loss 0.33037886023521423\n",
      "Epoch 3, training loss 0.27125558257102966, validation loss 0.33038830757141113\n",
      "Epoch 4, training loss 0.27178576588630676, validation loss 0.33042722940444946\n",
      "Epoch 5, training loss 0.27236074209213257, validation loss 0.33049848675727844\n",
      "Epoch 6, training loss 0.2728714942932129, validation loss 0.33058375120162964\n",
      "Epoch 7, training loss 0.2732606828212738, validation loss 0.3306611478328705\n",
      "Epoch 8, training loss 0.27352845668792725, validation loss 0.3307199776172638\n",
      "Epoch 9, training loss 0.27370473742485046, validation loss 0.3307611048221588\n",
      "Epoch 10, training loss 0.27381816506385803, validation loss 0.3307884633541107\n",
      "Epoch 11, training loss 0.2738843858242035, validation loss 0.33080488443374634\n",
      "Epoch 12, training loss 0.27390938997268677, validation loss 0.330811083316803\n",
      "Epoch 13, training loss 0.2738977074623108, validation loss 0.33080822229385376\n",
      "Epoch 14, training loss 0.27385571599006653, validation loss 0.3307977616786957\n",
      "Trained Weights:\n",
      "fc1.weight tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "fc1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "fc2.weight tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "fc2.bias tensor([-2.1056])\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model)\n",
    "\n",
    "print_auc(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81e3628-f4d9-43fa-a6cc-db154a2c435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409ed3f-da9b-46dd-bee0-fc8c384fd358",
   "metadata": {},
   "source": [
    "## 3. Random Initialization (Uniform or Normal)\n",
    "\n",
    "- Initializing weights randomly from a uniform or normal distribution\n",
    "- This is a common practice to break symmetry\n",
    "- The weights can be drawn from a distribution with a mean of 0 and a small variance\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.uniform_\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53e1b0e0-d78f-46ff-a06b-7323081e495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNormal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelNormal, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 10)\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=0.01)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        nn.init.normal_(self.fc2.weight, mean=0, std=0.01)\n",
    "        nn.init.normal_(self.fc2.bias, mean=0, std=0.01)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18452c76-58a1-4c2f-a0ec-a3563a53126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelNormal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8b72234-77b7-425d-820c-7f76ce79e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights and Bias:\n",
      "fc1.weight tensor([[ 2.7015e-03, -1.1805e-02,  7.5538e-03,  ..., -6.7114e-03,\n",
      "         -3.1334e-03, -8.3359e-03],\n",
      "        [ 4.6629e-03,  2.2604e-03,  5.6639e-04,  ..., -3.3982e-03,\n",
      "          5.0068e-05,  2.5671e-03],\n",
      "        [ 1.0387e-02,  1.0421e-02, -8.8279e-03,  ..., -2.1859e-02,\n",
      "         -4.2260e-03,  2.2272e-03],\n",
      "        ...,\n",
      "        [-6.8930e-04, -8.0790e-03, -1.3315e-02,  ..., -7.1349e-04,\n",
      "          1.5262e-02,  6.5075e-03],\n",
      "        [-4.8207e-03,  2.4344e-03, -2.3114e-02,  ...,  7.2144e-03,\n",
      "          2.1872e-02,  3.3376e-03],\n",
      "        [ 4.0601e-03, -2.9588e-04, -1.3732e-02,  ...,  8.7980e-03,\n",
      "         -6.6848e-03, -5.3351e-05]])\n",
      "fc1.bias tensor([-0.0119,  0.0024,  0.0031, -0.0046, -0.0095,  0.0017,  0.0149, -0.0175,\n",
      "        -0.0043,  0.0082])\n",
      "fc2.weight tensor([[ 0.0056,  0.0063, -0.0021, -0.0097, -0.0024, -0.0222,  0.0103, -0.0109,\n",
      "         -0.0061,  0.0064]])\n",
      "fc2.bias tensor([-0.0036])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "659443b9-fd7b-4a45-8d41-e17ce509bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.19017332792282104, validation loss 0.25739043951034546\n",
      "Epoch 1, training loss 0.18578745424747467, validation loss 0.2525328993797302\n",
      "Epoch 2, training loss 0.18091945350170135, validation loss 0.23968720436096191\n",
      "Epoch 3, training loss 0.1808839589357376, validation loss 0.23908965289592743\n",
      "Epoch 4, training loss 0.18148185312747955, validation loss 0.24301943182945251\n",
      "Epoch 5, training loss 0.1813228577375412, validation loss 0.24326050281524658\n",
      "Epoch 6, training loss 0.18113715946674347, validation loss 0.24277807772159576\n",
      "Epoch 7, training loss 0.18091465532779694, validation loss 0.24212539196014404\n",
      "Epoch 8, training loss 0.1807674765586853, validation loss 0.2413400560617447\n",
      "Epoch 9, training loss 0.1807074397802353, validation loss 0.24100083112716675\n",
      "Epoch 10, training loss 0.1806938797235489, validation loss 0.24066118896007538\n",
      "Epoch 11, training loss 0.18066376447677612, validation loss 0.24011307954788208\n",
      "Epoch 12, training loss 0.18063747882843018, validation loss 0.23977680504322052\n",
      "Epoch 13, training loss 0.18062615394592285, validation loss 0.23951514065265656\n",
      "Epoch 14, training loss 0.18058718740940094, validation loss 0.23920568823814392\n",
      "\n",
      "ROC AUC: 0.8591341608203664\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model)\n",
    "\n",
    "print_auc(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "625efa46-7cf4-4658-a1e1-18e9758d3c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights and Bias:\n",
      "fc1.weight tensor([[-0.5978, -0.6123, -0.5930,  ..., -0.6072, -0.6037, -0.6089],\n",
      "        [-0.5959, -0.5983, -0.6000,  ..., -0.6039, -0.6005, -0.5980],\n",
      "        [-0.2468, -0.2678, -0.2771,  ..., -0.2523, -0.2361, -0.2607],\n",
      "        ...,\n",
      "        [-1.0152, -0.9671, -1.1459,  ...,  0.6120,  0.9139, -0.6406],\n",
      "        [-0.1110, -0.1356, -0.1514,  ..., -0.0550, -0.0527, -0.1155],\n",
      "        [-0.5965, -0.6008, -0.6143,  ..., -0.5917, -0.6072, -0.6006]])\n",
      "fc1.bias tensor([-0.6124, -0.5982, -0.2501, -0.1897, -0.2216,  1.4588, -0.5857, -0.0634,\n",
      "        -0.1068, -0.5924])\n",
      "fc2.weight tensor([[-0.5949, -0.5942,  0.2637,  0.0727,  0.2300, -0.4897, -0.5903, -0.4697,\n",
      "          0.2174, -0.5941]])\n",
      "fc2.bias tensor([1.3593])\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469aea8-2126-4787-bf1d-ee710c8336f2",
   "metadata": {},
   "source": [
    "## 4. Xavier Initialization\n",
    "\n",
    "- This initialization is designed to work well with activation functions like tanh or sigmoid\n",
    "- The weights are initialized by drawing from a distribution with a mean of 0 and a variance of $\\frac{1}{number of input units}$\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f73f0e84-3484-4cd5-9694-44362bf89fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelXavier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelXavier, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 10)\n",
    "        nn.init.xavier_normal_(self.fc1.weight, gain=0.01)\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=0.01)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        nn.init.xavier_normal_(self.fc2.weight, gain=0.1)\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=0.01)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09e6a06d-3974-4617-8e45-dbdf875223d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelXavier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95bc25d8-c324-4c84-918c-1738caf495a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights and Bias:\n",
      "fc1.weight tensor([[-2.5966e-04, -1.0212e-03, -5.9727e-04,  ..., -4.7122e-04,\n",
      "          1.1819e-03, -5.7711e-06],\n",
      "        [-4.1296e-05, -5.4345e-04,  4.6347e-04,  ..., -1.7259e-03,\n",
      "         -1.0085e-03,  5.8473e-04],\n",
      "        [-6.5564e-04,  6.8766e-04,  5.6653e-04,  ..., -1.7195e-03,\n",
      "          6.2336e-04, -2.7550e-04],\n",
      "        ...,\n",
      "        [ 1.3343e-03, -4.9700e-04,  6.7129e-04,  ...,  5.7118e-04,\n",
      "         -1.7764e-03,  1.5043e-04],\n",
      "        [ 4.7460e-04,  1.4797e-03,  1.2245e-03,  ..., -1.1826e-03,\n",
      "         -7.4882e-04,  4.4720e-04],\n",
      "        [-8.8914e-04,  1.6558e-03,  1.9643e-03,  ...,  7.2793e-04,\n",
      "         -1.2370e-04, -9.4301e-04]])\n",
      "fc1.bias tensor([ 0.0079, -0.0061, -0.0105, -0.0165, -0.0117, -0.0026, -0.0103,  0.0005,\n",
      "        -0.0043, -0.0228])\n",
      "fc2.weight tensor([[ 0.0212, -0.0477,  0.0423,  0.0379, -0.0147,  0.0505,  0.0691, -0.0131,\n",
      "         -0.0659,  0.0159]])\n",
      "fc2.bias tensor([0.1183])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0267c52f-f0dc-4b9d-bc2b-ef12e732fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.19058926403522491, validation loss 0.2590586543083191\n",
      "Epoch 1, training loss 0.18031957745552063, validation loss 0.24043747782707214\n",
      "Epoch 2, training loss 0.18091513216495514, validation loss 0.23802395164966583\n",
      "Epoch 3, training loss 0.18106231093406677, validation loss 0.24094155430793762\n",
      "Epoch 4, training loss 0.18134278059005737, validation loss 0.24259433150291443\n",
      "Epoch 5, training loss 0.18132498860359192, validation loss 0.24312929809093475\n",
      "Epoch 6, training loss 0.18106289207935333, validation loss 0.24250295758247375\n",
      "Epoch 7, training loss 0.18086721003055573, validation loss 0.24153940379619598\n",
      "Epoch 8, training loss 0.18079720437526703, validation loss 0.2412882298231125\n",
      "Epoch 9, training loss 0.18072886765003204, validation loss 0.24089324474334717\n",
      "Epoch 10, training loss 0.1806761920452118, validation loss 0.24055491387844086\n",
      "Epoch 11, training loss 0.1806531697511673, validation loss 0.24002587795257568\n",
      "Epoch 12, training loss 0.1806255429983139, validation loss 0.23970744013786316\n",
      "Epoch 13, training loss 0.1806129366159439, validation loss 0.23944243788719177\n",
      "Epoch 14, training loss 0.1805928498506546, validation loss 0.23917196691036224\n",
      "\n",
      "ROC AUC: 0.8591331920559879\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model)\n",
    "\n",
    "print_auc(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d412cb57-cd29-46e3-b1e2-bf241a64f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights and Bias:\n",
      "fc1.weight tensor([[-6.0081e-01, -6.0157e-01, -6.0114e-01,  ..., -6.0102e-01,\n",
      "         -5.9937e-01, -6.0055e-01],\n",
      "        [-4.1296e-05, -5.4345e-04,  4.6347e-04,  ..., -1.7259e-03,\n",
      "         -1.0085e-03,  5.8473e-04],\n",
      "        [-6.5564e-04,  6.8766e-04,  5.6653e-04,  ..., -1.7195e-03,\n",
      "          6.2336e-04, -2.7550e-04],\n",
      "        ...,\n",
      "        [-2.9917e-01, -3.6219e-01, -3.3916e-01,  ..., -1.7079e-01,\n",
      "         -1.9885e-01, -3.1959e-01],\n",
      "        [-2.2273e+00, -1.9612e+00, -2.3008e+00,  ...,  1.7770e+00,\n",
      "          2.5582e+00, -9.8628e-01],\n",
      "        [-6.0082e-01, -5.9848e-01, -5.9813e-01,  ..., -5.9934e-01,\n",
      "         -6.0007e-01, -6.0102e-01]])\n",
      "fc1.bias tensor([-0.5926, -0.0061, -0.0105, -0.0165, -0.8813, -0.6031, -0.6108, -0.2727,\n",
      "         1.4858, -0.6231])\n",
      "fc2.weight tensor([[-0.5794, -0.0477,  0.0423,  0.0379,  0.9200, -0.5500, -0.5314,  0.2287,\n",
      "         -0.4831, -0.5781]])\n",
      "fc2.bias tensor([1.3658])\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb35cd-6399-4537-8f7b-44195c7f25af",
   "metadata": {},
   "source": [
    "## 5. He Initialization\n",
    "\n",
    "- This initialization is designed for ReLU and its variants\n",
    "- The weights are initialized by drawing from a distribution with a mean of 0 and a variance of $\\frac{2}{number of input units}$\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_\n",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c795b52-67b9-4a1a-8067-0094eaf6de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHe(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelHe, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 10)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=0.01)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        nn.init.xavier_normal_(self.fc2.weight, gain=0.1)\n",
    "        nn.init.normal_(self.fc1.bias, mean=0, std=0.01)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de428a69-b26e-4433-8c81-59942c867489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelHe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f49c818-0b60-486b-a3f2-1ef63c9cd44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights and Bias:\n",
      "fc1.weight tensor([[-3.1251e-02,  1.0257e-01,  2.6924e-02,  ...,  1.1328e-01,\n",
      "          6.5151e-02,  7.2830e-02],\n",
      "        [ 1.6555e-01,  2.9367e-01, -3.3813e-02,  ...,  1.5567e-01,\n",
      "          1.8278e-01,  1.9932e-02],\n",
      "        [ 2.4959e-04, -7.1816e-02, -1.0658e-01,  ..., -5.7668e-02,\n",
      "          1.9273e-02,  1.2826e-02],\n",
      "        ...,\n",
      "        [-8.7776e-02,  7.0288e-02,  9.0008e-02,  ...,  4.0887e-02,\n",
      "         -2.0022e-02, -1.2602e-02],\n",
      "        [-1.0190e-01,  1.3763e-02,  5.2266e-02,  ..., -7.9132e-02,\n",
      "          1.0709e-01,  3.1396e-02],\n",
      "        [ 1.8228e-01,  7.0387e-03,  3.3341e-02,  ...,  4.2306e-02,\n",
      "          2.6777e-02,  4.1782e-02]])\n",
      "fc1.bias tensor([ 1.0474e-02,  1.3299e-02, -2.0440e-02,  4.4785e-03, -2.7267e-02,\n",
      "        -4.9259e-03,  5.9543e-04,  1.3017e-02, -3.7155e-05, -1.0386e-02])\n",
      "fc2.weight tensor([[ 0.0227, -0.0470, -0.0505, -0.0272, -0.0105, -0.1039,  0.0655, -0.0221,\n",
      "         -0.0168,  0.0188]])\n",
      "fc2.bias tensor([-0.2996])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35913e73-2612-4232-87d5-36126e885cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.18820826709270477, validation loss 0.24117988348007202\n",
      "Epoch 1, training loss 0.18081921339035034, validation loss 0.23843751847743988\n",
      "Epoch 2, training loss 0.18089459836483002, validation loss 0.2381526380777359\n",
      "Epoch 3, training loss 0.1811688095331192, validation loss 0.24073772132396698\n",
      "Epoch 4, training loss 0.18142426013946533, validation loss 0.24262553453445435\n",
      "Epoch 5, training loss 0.18137603998184204, validation loss 0.24316850304603577\n",
      "Epoch 6, training loss 0.18109843134880066, validation loss 0.2425648421049118\n",
      "Epoch 7, training loss 0.18090561032295227, validation loss 0.241700679063797\n",
      "Epoch 8, training loss 0.18082751333713531, validation loss 0.24138084053993225\n",
      "Epoch 9, training loss 0.18075741827487946, validation loss 0.24106821417808533\n",
      "Epoch 10, training loss 0.1807030439376831, validation loss 0.24072396755218506\n",
      "Epoch 11, training loss 0.18067608773708344, validation loss 0.240186870098114\n",
      "Epoch 12, training loss 0.1806517392396927, validation loss 0.239900141954422\n",
      "Epoch 13, training loss 0.18061883747577667, validation loss 0.23957733809947968\n",
      "Epoch 14, training loss 0.18060851097106934, validation loss 0.23933303356170654\n",
      "\n",
      "ROC AUC: 0.8591269035854622\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model)\n",
    "\n",
    "print_auc(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10563a49-a4c8-40ac-9071-2ce9bb7b7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights and Bias:\n",
      "fc1.weight tensor([[-0.6318, -0.4980, -0.5736,  ..., -0.4873, -0.5354, -0.5277],\n",
      "        [-0.2023, -0.1256, -0.4141,  ..., -0.1273, -0.0853, -0.3556],\n",
      "        [-0.5871, -0.6607, -0.6977,  ..., -0.6359, -0.5577, -0.5733],\n",
      "        ...,\n",
      "        [-0.5932, -0.4417, -0.4105,  ..., -0.4394, -0.5163, -0.5137],\n",
      "        [-0.3495, -0.2556, -0.2155,  ..., -0.2802, -0.0954, -0.2243],\n",
      "        [-0.4182, -0.5935, -0.5672,  ..., -0.5582, -0.5737, -0.5587]])\n",
      "fc1.bias tensor([-0.5901, -0.3308, -0.6020, -0.3135, -0.5553,  1.4424, -0.6000, -0.4846,\n",
      "        -0.2364, -0.6109])\n",
      "fc2.weight tensor([[-0.5778, -0.1988,  0.5601, -0.0260,  0.5166, -0.4950, -0.5350,  0.3654,\n",
      "          0.1805, -0.5818]])\n",
      "fc2.bias tensor([1.3718])\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained Weights and Bias:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0097af-3854-4d80-9de9-f2f790af923c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
